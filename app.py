# -*- coding: utf-8 -*-
"""Handigit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iw1zsp2x_n84rkaXWGfIf6D48jYJoNZX
"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical

# Load dataset
(X_train, y_train), (X_test, y_test) = mnist.load_data()

# Reshape data to fit the CNN input (samples, height, width, channels)
X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32') / 255.0
X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32') / 255.0

# One-hot encode labels
y_train_cat = to_categorical(y_train, 10)
y_test_cat = to_categorical(y_test, 10)

# Print shapes for confirmation
print("Training Data Shape:", X_train.shape)
print("Testing Data Shape:", X_test.shape)

# Build CNN model
model = Sequential([
    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),
    MaxPooling2D(pool_size=(2, 2)),

    Conv2D(64, kernel_size=(3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')  # Output layer for 10 digits
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train_cat, epochs=5, batch_size=128, validation_split=0.1)

# Evaluate the model on the test dataset
test_loss, test_acc = model.evaluate(X_test, y_test_cat)
print(f"\n Test Accuracy: {test_acc * 100:.2f}%")

# Save the model to a file
model.save("mnist_cnn_model.h5")
print(" Model saved as mnist_cnn_model.h5")

from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode
import cv2
import numpy as np
from PIL import Image
import io

def take_photo(filename='photo.jpg', quality=0.8):
    js = Javascript('''
        async function takePhoto(quality) {
          const div = document.createElement('div');
          const capture = document.createElement('button');
          capture.textContent = 'ðŸ“· Capture Photo';
          div.appendChild(capture);
          document.body.appendChild(div);

          const stream = await navigator.mediaDevices.getUserMedia({video: true});
          const video = document.createElement('video');
          video.srcObject = stream;
          await video.play();

          div.insertBefore(video, capture);

          await new Promise((resolve) => capture.onclick = resolve);

          const canvas = document.createElement('canvas');
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          canvas.getContext('2d').drawImage(video, 0, 0);
          stream.getTracks().forEach(track => track.stop());
          video.remove();
          capture.remove();

          const dataURL = canvas.toDataURL('image/jpeg', quality);
          div.remove();
          return dataURL;
        }
        takePhoto({quality: %s});
    ''' % quality)
    display(js)
    data = eval_js("takePhoto()")
    binary = b64decode(data.split(',')[1])
    with open(filename, 'wb') as f:
        f.write(binary)
    return filename

photo_path = take_photo()
print(f" Photo captured and saved to {photo_path}")

def predict_digit(image):
    import cv2
    import numpy as np

    # Convert RGB to Grayscale if needed
    if image.ndim == 3:
        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)

    # Resize, invert, normalize, and reshape
    image = cv2.resize(image, (28, 28))
    image = cv2.bitwise_not(image)
    image = image.astype('float32') / 255.0
    image = image.reshape(1, 28, 28, 1)

    # Predict
    pred = model.predict(image)
    predicted_digit = np.argmax(pred)
    confidence = np.max(pred)

    return f" Predicted Digit: {predicted_digit} (Confidence: {confidence:.2f})"

!pip install gradio --quiet

import gradio as gr
import numpy as np
import cv2
from tensorflow.keras.models import load_model

# Load your trained model
model = load_model("mnist_cnn_model.h5")

def predict_digit(image):
    try:
        # Convert to grayscale if not already
        if image.ndim == 3:
            image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)

        # Resize to 28x28
        image = cv2.resize(image, (28, 28))

        # Invert colors
        image = cv2.bitwise_not(image)

        # Normalize and reshape
        image = image.astype("float32") / 255.0
        image = image.reshape(1, 28, 28, 1)

        # Predict
        pred = model.predict(image)
        predicted_digit = np.argmax(pred)
        confidence = np.max(pred)

        return f" Predicted Digit: {predicted_digit} (Confidence: {confidence:.2f})"
    except Exception as e:
        return f"Error: {str(e)}"

# No shape argument here
gr.Interface(
    fn=predict_digit,
    inputs=gr.Image(type="numpy"),  # just type="numpy"
    outputs="text",
    title=" Handwritten Digit Recognizer (MNIST-style)"
).launch()